\batchmode
%\documentclass[letterpaper,oneside]{article}
% letterpaper,10pt,oneside,onecolumn,final
\documentclass[hidelinks]{article}

\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\input glyphtounicode
\pdfgentounicode=1

\usepackage[english]{babel}
\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\addbibresource{hops-development.bib}

\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{csquotes}
\usepackage{textcomp}
\usepackage{outlines}
\usepackage{enumitem}
\usepackage{marginnote}
\usepackage{soul}

\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage{placeins}

\let\Oldsection\section
\renewcommand{\section}{\FloatBarrier\Oldsection}

\let\Oldsubsection\subsection
\renewcommand{\subsection}{\FloatBarrier\Oldsubsection}

\let\Oldsubsubsection\subsubsection
\renewcommand{\subsubsection}{\FloatBarrier\Oldsubsubsection}

\makeatletter
\newcommand\urlfootnote@[1]{\footnote{\url@{#1}}}
\DeclareRobustCommand{\urlfootnote}{\hyper@normalise\urlfootnote@}
\makeatother


\usepackage{color}



%\usepackage{lineno}
%\linenumbers

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\definecolor{lightgray}{gray}{0.75}




\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{subcaption}
% \usepackage{lineno}
\usepackage{listings}
\usepackage{microtype}
\usepackage{placeins}
\usepackage[x11names]{xcolor}
\usepackage{footnote}


\usepackage[T1]{fontenc}
\usepackage[scaled]{beramono}
\newcommand\Small{\fontsize{9}{9.2}\selectfont}
\newcommand\Normal{\fontsize{12}{12.3}\selectfont}
\newcommand*\LSTfont{\Small\ttfamily\SetTracking{encoding=*}{-60}\lsstyle}
\newcommand*\LSTfontNormal{\Normal\ttfamily\SetTracking{encoding=*}{-60}\lsstyle}


\usepackage{listings}


\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\LSTfont,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{gray},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frameshape={RYR}{Y}{Y}{RYR},	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=C++,                 % the language of the code
  otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=none,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{gray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{red},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}


\usepackage{tabularx}
    \newcolumntype{L}{>{\raggedright\arraybackslash}X}


\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.geometric, arrows}
\pgfplotsset{compat=1.11}
% but see adjustments below
\usepackage[margin=0.9in]{geometry}





\newcommand\tikzmark[2]{%
  \tikz[remember picture,overlay]\node[arrow,draw] (#1) {#2};}


%\usepackage[printwatermark]{xwatermark}
%\newwatermark[pages=2-30,color=gray!25,angle=45,scale=5,xpos=0,ypos=0]{DRAFT}

\usepackage{etoolbox}
\makeatletter
\patchcmd{\@verbatim}
  {\verbatim@font}
  {\verbatim@font\tiny}
  {}{}
\makeatother

\usepackage{ifthen}

\let\endtitlepage\relax

\newcommand{\FIXME}[1]{{\bf {\color{red} #1}}}
\newcommand{\nuHOPS}{{\bf {\color{dkgreen} (new)HOPS}}}

% Title Page
\title{ \textbf{MSRI HOPS Re-development Specification} }
\author{
\large Geoff Crew and John Barrett \\
\Large MIT Haystack Observatory}
\date{Rough Draft Version 0.1, \today}

\addtolength{\oddsidemargin}{.20in}
\addtolength{\evensidemargin}{.20in}
\addtolength{\textwidth}{-.50in}
\addtolength{\topmargin}{.100in}
\addtolength{\textheight}{-.100in}


\begin{document}
\maketitle

%\vspace{1.5in}

\tiny
\tableofcontents
\normalsize
\newpage
%\listoffigures
%\newpage
%\listoftables
%\newpage

%   * Architecture definition
%   * Language selection
%   * Build system selection
%   * Parallel support definition
%   * Interactivity definition
%   * External package identification
%   * New objects specification
%   * New library specification
%   * New program specification 


\section{Architecture}

The goal of the re-developed HOPS architecture is provide a component-based design which allows for a greater degree of flexibility 
in the types of operations that may be applied to VLBI data during fringe fitting, and avoid the semi-monolithic approach used in the past.
To do this, the software package to be delivered will primarily comprise of a set of loosely coupled libraries which can be composed
into an variety of calibration and fringe-fitting applications. Moreover, rather than attempting to identify and categorize all manner of data
and data manipulation which may be required by future observations at the outset, a primary goal of this project is to provide a
relatively flexible set of data types and a plugin interface so as to allow for future extensions with minimal revision to the existing code.
Additionally, the high-level interface should support both command-line and pipelinable commanding as well as a modern graphical interface
for interactive use.

For the foreseeable future, the main source of input data to this software will be provided by the DiFX correlator. However, this may not always 
be the case, so in order to decouple the correlator from the post-processing software a conversion utility must be provided. This follows
the same paradigm as the current code (difx2mark4), except that we propose that this conversion utility operate mainly as a transparent pass-through, merely
converting the correlator output into the native post-processing format, rather than applying any initial calibration (e.g. auto-corrs) or corrections.

Once the data has been converted to the native post-processing format additional manipulation will take place in several stages, such as data-flagging, 
a priori phase/delay calibration, fringe-fitting, and post-fringe-fitting calibration. Finally the data will be made available for export to archival formats
(e.g. HDF5) and possibly other analysis packages.

Finally, it is a requirement to retain current capabilities in essentially unchanged form.  Additionally, recognizing HOPS' long history
and acknowledging that the Earth and the EHT have a long future ahead of them, the re-organized code should be designed to be relatively
easy to maintain for the several decades to come.

\textbf{TODO - expand on this, add diagram of data flow and add diagram of control/data-flow in 'fringe-fitter'.}

% Design language choices
\section{Language, Build and Version Control System}

Several aspects need to be taken into account when deciding on a choice of programming language for this project. Namely, some of these are:
\begin{enumerate}
 \item Availability of software developer expertise.
 \item The inherent performance attainable with a specific language.
 \item Availability of high performance open source utility libraries for math, I/O, etc.
 \item The primary language of the existing code base (C).
 \item The accessibility and ease of extensibility of the project by users with varying levels of experience
\end{enumerate}

Obtaining a reasonable balance between these considerations is difficult with a single language. Therefore we
plan to develop a multi-language project, wherein the base computation layer is handled within C/C++,
but additional data manipulation can be done via optional Python plugins embedded within the aapplication
or independently by external Python scripts which have access to some of the underlying application libraries. 
C++ is a good choice given current personnel and developer expertise, and being a super-set of the C language
it provides the ability to reuse of portions of the existing C code base with little to no change, while also adding modern language features
(templates, classes and inheritance, const. correctness, function overloading, etc.). A combined C/C++ approach 
allows for much easier memory management (currently handled rather painfully in the existing HOPS code base) and also
enables the use of a wide variety of open source libraries, not least of which is the built in standard template library
which provides access to a wide collection of basic data types (strings, vectors, maps, etc) and algorithms (searching, sorting, etc.)
which will reduce the required amount of maintenance of internal code and reliance on external libraries. 

Further augmenting C/C++ libraries with inter-language communication to Python can be done via a wide variety of mature tools 
(ctypes, boost.Python, SWIG, pybind11, etc.), and will increases the ease at which outside users can augment the software. 
Since Python 2 is no longer supported, all new development will be Python 3.

\marginnote{\tiny{%
Neither of these transitions need occur immediately, and GC would argue that they can happen in parallel.
It may be important to show good progress with the code earlier rather than later.}}
The build system for this project will be the CMake build system \urlfootnote{https://cmake.org}, and version control will proceed through a locally 
hosted (Haystack) git repository. The CMake build system is generally easier to maintain than the current autotools system used by HOPS when faced with the complexities of a multi-language project. It also allows for a more user-friendly configuration at the time of compilation, as the user can be presented with a menu providing options which are dependent on the available set of tools/libraries that are currently installed and detected on the users system. It is also suggested to move to the git version control (over Subversion) system for several reasons\urlfootnote{http://git.wiki.kernel.org/index.php/GitSvnComparsion}. Two of which that particularly stand out are:

\begin{enumerate}
 \item  Its access control model lets the repository owner maintain local control over the code base while providing and the ability to accept changes from external entities without them needing permissions. This will make it much easier to leverage community contributions if so desired at some point in the future.
 \item The manner in which branching and merging is handled in git is less cumbersome as it tracks the complete source tree. This is especially important when a project contains multiple independent tools that have separate development schedules. For example this obviates the need for a `virtualtrunk' -- the model used by DiFX. 
\end{enumerate}


\section{Parallel processing}

The existing fringe-fitting process is largely a data-parallel process operating on individual baselines with no inter-process
communication. This lends itself easily to simple parallelism using multiple independent processes (SPMD), which has been exploited
\cite{blackburn2019eht} to deal with the EHT data volume. However, this approach eliminates the ability to simultaneously fit for global or station-based
parameters and requires multiple iterations in order to apply successive calibration/corrections. Therefore, if some calibration tasks are to be
done simultaneously with fringe-fringe fitting, this will require both a substantial architectural change from the current fitting algorithm, but
also necessarily reduce the degree of (simple) parallelism available. To accommodate this, some parallel processing will have to be addressed
within the application. To do this we will use a multi-staged approach during the course of development.

\marginnote{\tiny{%
At the same time, the code must continue to function if such acceleration is not possible.  }}
Initially, the software to be developed under this project will focus on a simple single-threaded implementation, whereupon careful
profiling will inform us of the largest computational bottlenecks. For example, in the current HOPS code the majority of
the computation time is spent in a single routine (vrot.c, which is essentially just multiplying two complex numbers) that is applied over
a large array of data. This sort of task can easily be parallelized on modern multi-core architectures using the SIMD approach. We propose to use OpenCL
for this purpose given its support on a wide variety of architectures (mult-core CPUs, GPUS, hardware accelerators, etc.).


This type of parallelism exploits vector instructions and/or multiple processors to execute the similar operations over wide swaths of data. while given current experience with the existing HOPS leads us to expect that SIMD parallelism should largely be adequate to accelerate fringe fitting, if during the process of development it is discovered that a thread-based model (MIMD, where each parallel thread follows a semi-independent code pathway) could be more advantageous, then we propose to use OpenMPI framework to implement this. The reason being, that while OpenMPI does have a larger development overhead than most other threading libraries (e.g. pthreads, c++11 threads, etc.) it can be easily scaled beyond a single computer when and if needed. However, it should be noted that by necessity, any OpenMPI implementation must be developed as an independent executable (although it would be able to take advantage of any available libraries and SIMD policies present).
\marginnote{\tiny{%
And while we should architect to allow this, it is not clear that this \textbf{must} be accomplished within the scope of the current project.}}

\section{External Package Selection}

To the extent possible the software to be developed in this project should make all external dependencies optional whenever possible. That is to say, that
while some features may be missing if an optional external package is missing, the core functionality of the software should not be affected. For example, if the fast Fourier transform library FFTW3 is missing, the code should fall back to an internal implementation (which is allowed to be slower), but which produces equivalent output. Likewise, while an effort should be made to support portability of the output data into useful downstream formats (HDF5), this should not preclude the use of a native format capable of storing the same data for development and debugging purposes. 

\marginnote{\tiny{%
Note that if we opt to retain a “frozen” copy of the existing version, we retain additional fallbacks.}}
The following table is a preliminary list of which external packages are expected to be incorporated as required or optional dependencies. If an optional package is missing on a user's machine the software will default to a fallback option (if available) or disable the features which require that particular package.

\marginnote{\tiny{%
It's not clear to me that we want to use plplot.  We \textbf{need} something that makes PDF rendering possible.
All of the existing plots (aedit's included) could be trivially redone in gnuplot or python or \dots.}}
\begin{center}
\begin{table}[h!]
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{|c|c|c|c|}
\hline
Name & Optional/Required? & Purpose & Fallback option \\ \hline
C++11 STL & Required & Standard template library & None \\ \hline
Python &  Required & Scripting language interpreter & None \\ \hline
pybind11/boost.Python/SWIG & Required & C/C++ $\leftrightarrow$ Python interface and bindings & None \\ \hline
OpenCL & Optional & SIMD parallelism & Single-threaded implementation \\ \hline
OpenMPI & Optional & MIMD parallelism & Single-threadd implementation \\ \hline
FFTW3 & Optional & fast Fourier transform acceleration & TBD native code \\ \hline
GSL & Optional & Linear algebra and special functions & TBD native code \\ \hline
HDF5 & Optional & File input/output & TBD native binary format \\ \hline
PLPlot & Optional & plotting library & None \\ \hline
difxio & Required & DiFX I/O library - file converter only & None \\ \hline
\end{tabular}
\end{adjustbox}
\caption{List of optional/required dependencies.}
\label{tab:dep}
\end{table}
\end{center}


\section{Objects specification}

\label{sec:objects}


Generally speaking the code will be organized around roughly two object type categories involved in the structure of the new HOPS. These are as follows:

\begin{enumerate}
 \item Data Containers: These serve to organize the visibility data and metadata associated with an observation.
 \item Data Operators: These evaluate a function or perform some transformation on a given data container. Their operation may by directed by set of externally defined conditions (i.e. defined outside the data containers upon which they operate).
\end{enumerate}

\subsection{Data Containers}

The existing HOPS code base relies on a fixed number of \texttt{C} structs to organize and present the data related to an observation. The strict memory layout of these structures has the advantage of making them cross-machine compatible, which is necessary since these structures are also used as the core components of the Mark-4 I/O library. However, a notable disadvantage of this rigid design is the degree of difficulty encountered in making changes to the existing data structures, or adding new data types in order to accommodate additional information which was not originally envisioned at the time the library was written.

To make the data structures more flexible we intend to decouple the in-memory data layout from the file I/O, so they do not necessarily need to be byte-for-byte copies.
Furthermore, to the extent possible, the in-memory data structures should be classes which provide access via a key-value pair mechanism so as to avoid exposing the private internal storage layout to the routines needing access to subsets of the data.

In a strictly typed language such as \texttt{C}, flexible data structures have a high degree of code overhead, not only in the management of dynamic memory allocation, but more severely in the conversion of data types and typecasting. To ameliorate this we propose to exploit \texttt{C++11}'s variadic template mechanism, which allows for the transformation of type-agnostic class lists into concrete class types or hierarchies at compile time. This makes it possible to store disparate types (known at compile time) within in the same object that are indexed and can be retrieved by the same type of key (e.g. a name string). 

We propose the following basic set of class templates be used to construct most in-memory objects used for the manipulation of correlated observation data and its associated metadata:
\begin{enumerate}
 \item ScalarContainer - encapsulates scalar-like data with associated units
 \item VectorContainer - encapsulates vector-like data with associated units
 \item TensorContainer - encapsulates rank-N tensor-like data with associated item and axis (vector) units
 \item HeterogenousContainer - encapsulates any of the above types
\end{enumerate}
These template classes are to serve as a simple wrapper around the management of the raw memory needed to store a data item and keep track of its associated unit(s), and (if applicable) its axis values and their units.

Listing \ref{lst:objects} gives a brief sketch (without implementation) of the class templates for these data container objects, while listing \ref{lst:visib} gives a simple example of what template declaration of an object storing visibility data from an observation over multiple baselines and polarization products might look like.

\lstinputlisting[language=C++,label={lst:objects},caption=Data object templates]{./code/data_objects.hh}

\lstinputlisting[language=C++,label={lst:visib},caption=Visibility object type]{./code/visibilities.hh}

\subsection{Data operators}

The data operator classes are meant to organize the mathematic manipulations which are to be performed on the data containers. For example, many of the operations performed in the existing HOPS code-base (such as the application of a priori phase calibration) are relatively trivial linear transformations applied to the visibility data. However, they are currently intertwined with a large amount of control logic which obscures the basic data pathway (e.g see postproc/fourfit/norm\_fx.c)
Most unary or binary operations that are to applied to visibility or other data residing in TensorContainers such as scaling, multiplication, transposition, summation, Fourier transformation, etc. will be made available as individual classes inheriting from the same interface. A uniform class interface will allow these data operators to be composed or modified to create more complicated composite operators or strung together to accomplish data pipelines of arbitrary complexity. An additional advantage of encapsulating individual operations is that any SIMD parallel-processing extension used to accelerate data processing can be made opaque to the user. Listing \ref{lst:operators} gives a brief sketch of the class templates generalizing the data operators.


\lstinputlisting[language=C++,label={lst:operators},caption=Data operator templates]{./code/data_operators.hh}


\section{Interactivity definition}

Interactivity with the user will proceed primarily through a python scripting interface. This avoids the need to develop a separate scripting language, as the python interpreter can be embedded in the application. Access to library objects will be exposed via python bindings, so that a user may have direct access to the data containers, and can implement
external routines which can be insert as a data operator. \st{Real-time interactivity is not planned to be implemented.}
\marginnote{\tiny{Actually, real-time interaction with the user such as is provided by aedit is \textbf{required}}}

\section{Libraries and executables}

\subsection{Libraries}

The software to be delivered will be presented largely as set of libraries with several executables which utilize them. These libraries will be organized by their primary function and are expected to consist of the following:

\begin{enumerate}
 \item Core - Common template and abstract base classes, messaging and other utilities.
 \item Math - Common mathematical functions and minimization routines.
 \item Data containers and native I/O - Definitions of the in-memory data objects and a simple binary I/O interface. 
 \item Data operators - Definitions of data operations 
 \item Builders and process management - Provides classes which constructs data operators and the pipeline which organizes them from user input.
 \item Plugins:
 \begin{enumerate}
    \item HDF5 I/O - Converts the in-memory data objects to/from an archival HDF5 file.
    \item Plotting - Utilities to generate plots for data exploration (e.g. fringe-plots).
    \item Python interface - Interpreter for user scripts and python bindings to C/C++ objects.
    \item SIMD extensions (OpenCL) - Parallel implementation of some set of data operators
 \end{enumerate}
\end{enumerate}


\subsection{Executables}

The executables to be delivered will largely be composed through re-use of the library code and at a minimum will consist of the following (though not necessarily
named as such):

\begin{enumerate}
 \item DiFX2Input  - difx2mark4 equivalent, converts correlator (difx) data into native input format.
 \item Station utilities  - converts station calibration data (e.g. ANTAB) files into native input format.
 \item FringeFitter - fourfit-equivalent, accepts a user script for configuration and direction and applies it to the visibility data.
 \item DataInspect - data inspection tool, dumps data objects to a human readable format.
 \item FringePlot  - plotting tool, creates fringe-plots and all graphical data exploration.
 \item HDF5Export  - converts any native formats into an HDF5 format for access by external programs.
\end{enumerate}




%
% above to be deleted after merger
%
\newpage
\addtocounter{section}{1}
\renewcommand{\refname}{\thesection. References}

\bibstyle{plainurl}
%\section{References}
%% increment reference section number
\label{sec:references}

%\printbibliography[title={\ref{sec:reference} References}]
\printbibliography
%\bibliography{hops-development}
%\bibliographystyle{plain}


\end{document}
